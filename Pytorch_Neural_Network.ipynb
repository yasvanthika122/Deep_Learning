{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasvanthika122/Deep_Learning/blob/main/Pytorch_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp6DMVpZm0yE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081))])"
      ],
      "metadata": {
        "id": "CPD8lCZInJOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.MNIST('data',train=True,\n",
        "                             download=True,\n",
        "                             transform=transform)"
      ],
      "metadata": {
        "id": "CwXG0aSUp6M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(train_dataset,\n",
        "                                         batch_size=64,\n",
        "                                         shuffle=True)"
      ],
      "metadata": {
        "id": "BmeMcDtnqOsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)  # Added layer with 64 neurons\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))  # Applying relu activation to the output of the second layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "# Create an instance of the Neural network\n",
        "net = Neural()\n"
      ],
      "metadata": {
        "id": "syWjRFcLrANF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the loss function and Optimizer\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.5)\n"
      ],
      "metadata": {
        "id": "Za7QI7Px1bpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,target) in enumerate (train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output=net(data)\n",
        "    loss =criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 100==0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPVPAZe613P_",
        "outputId": "22ac3161-30b2-4c0a-8b6c-5691e36f2af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.289772\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.314959\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.704873\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.548614\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.416333\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.440596\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.451036\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.154287\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.380723\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.336520\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.253352\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.318042\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.126446\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.304883\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.138287\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.242519\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.277581\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.210209\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.248613\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.140642\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.231772\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.218853\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.130624\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.094554\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.187752\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.152221\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.236309\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.347721\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.207985\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.203793\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.184586\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.282145\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.123355\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.058929\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.161616\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.164215\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.165452\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.346570\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.081876\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.126210\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.233734\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.054129\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.135471\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.072827\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.121172\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.118927\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.292240\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.154175\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.087691\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.091493\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.210922\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.103559\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.162636\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.202966\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.064780\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.041364\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.076548\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.063204\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.076154\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.136040\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.033453\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.153236\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.057942\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.085458\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.095894\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.013771\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.055811\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.058769\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.056326\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.040373\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.028998\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.070019\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.053286\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.061893\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.057067\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.067591\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.023686\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.095295\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.034213\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.128734\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.105170\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.117876\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.071788\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.040622\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.120953\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.115521\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.093488\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.083451\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.020296\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.049986\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.018529\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.035345\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.047957\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.027183\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.107225\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.091915\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.035279\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.096687\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.027223\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.028910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the test data and test the model\n",
        "\n",
        "test_dataset=datasets.MNIST('data',train=False,download=True,transform=transform)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=1000,shuffle=True)\n",
        "correct=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "  output=net(data)\n",
        "  _,predicted=torch.max(output.data,1)\n",
        "  total+=target.size(0)\n",
        "  correct+=(predicted==target).sum().item()\n"
      ],
      "metadata": {
        "id": "sD2KucWC2C38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6MdYowq2UXV",
        "outputId": "b888c8e3-2925-4621-fce9-f85b24f98d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcfwJ9-O-fqA",
        "outputId": "696f7513-2a24-43ec-ae0a-823f6cddd45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16378949.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 302333.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5500223.78it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 12575583.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Epoch [1/5], Step [100/938], Loss: 1.0372\n",
            "Epoch [1/5], Step [200/938], Loss: 0.6021\n",
            "Epoch [1/5], Step [300/938], Loss: 0.5557\n",
            "Epoch [1/5], Step [400/938], Loss: 0.5045\n",
            "Epoch [1/5], Step [500/938], Loss: 0.4842\n",
            "Epoch [1/5], Step [600/938], Loss: 0.4618\n",
            "Epoch [1/5], Step [700/938], Loss: 0.4370\n",
            "Epoch [1/5], Step [800/938], Loss: 0.4492\n",
            "Epoch [1/5], Step [900/938], Loss: 0.4246\n",
            "Epoch [2/5], Step [100/938], Loss: 0.3999\n",
            "Epoch [2/5], Step [200/938], Loss: 0.3983\n",
            "Epoch [2/5], Step [300/938], Loss: 0.3687\n",
            "Epoch [2/5], Step [400/938], Loss: 0.3992\n",
            "Epoch [2/5], Step [500/938], Loss: 0.4035\n",
            "Epoch [2/5], Step [600/938], Loss: 0.3873\n",
            "Epoch [2/5], Step [700/938], Loss: 0.3813\n",
            "Epoch [2/5], Step [800/938], Loss: 0.3605\n",
            "Epoch [2/5], Step [900/938], Loss: 0.3816\n",
            "Epoch [3/5], Step [100/938], Loss: 0.3505\n",
            "Epoch [3/5], Step [200/938], Loss: 0.3544\n",
            "Epoch [3/5], Step [300/938], Loss: 0.3719\n",
            "Epoch [3/5], Step [400/938], Loss: 0.3418\n",
            "Epoch [3/5], Step [500/938], Loss: 0.3622\n",
            "Epoch [3/5], Step [600/938], Loss: 0.3459\n",
            "Epoch [3/5], Step [700/938], Loss: 0.3384\n",
            "Epoch [3/5], Step [800/938], Loss: 0.3553\n",
            "Epoch [3/5], Step [900/938], Loss: 0.3503\n",
            "Epoch [4/5], Step [100/938], Loss: 0.3373\n",
            "Epoch [4/5], Step [200/938], Loss: 0.3251\n",
            "Epoch [4/5], Step [300/938], Loss: 0.3227\n",
            "Epoch [4/5], Step [400/938], Loss: 0.3438\n",
            "Epoch [4/5], Step [500/938], Loss: 0.3298\n",
            "Epoch [4/5], Step [600/938], Loss: 0.3285\n",
            "Epoch [4/5], Step [700/938], Loss: 0.3295\n",
            "Epoch [4/5], Step [800/938], Loss: 0.3206\n",
            "Epoch [4/5], Step [900/938], Loss: 0.3145\n",
            "Epoch [5/5], Step [100/938], Loss: 0.3227\n",
            "Epoch [5/5], Step [200/938], Loss: 0.3237\n",
            "Epoch [5/5], Step [300/938], Loss: 0.3091\n",
            "Epoch [5/5], Step [400/938], Loss: 0.3154\n",
            "Epoch [5/5], Step [500/938], Loss: 0.3063\n",
            "Epoch [5/5], Step [600/938], Loss: 0.2934\n",
            "Epoch [5/5], Step [700/938], Loss: 0.3080\n",
            "Epoch [5/5], Step [800/938], Loss: 0.2999\n",
            "Epoch [5/5], Step [900/938], Loss: 0.3017\n",
            "Accuracy on the test set: 86.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define a more complex neural network class\n",
        "class DeepNeural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNeural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)  # Output layer with 10 classes for FashionMNIST\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc5(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Load FashionMNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the deep neural network\n",
        "net = DeepNeural()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Learning rate scheduler\n",
        "\n",
        "# Training the network\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()  # Update learning rate at the end of each epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Testing the network\n",
        "net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the test set: {100 * accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLkRMqNHBzoC",
        "outputId": "6f51dd23-10ac-4b29-a2b3-8574bc5cd508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.8725\n",
            "Epoch [2/15], Loss: 0.6337\n",
            "Epoch [3/15], Loss: 0.5793\n",
            "Epoch [4/15], Loss: 0.5408\n",
            "Epoch [5/15], Loss: 0.5202\n",
            "Epoch [6/15], Loss: 0.4627\n",
            "Epoch [7/15], Loss: 0.4456\n",
            "Epoch [8/15], Loss: 0.4381\n",
            "Epoch [9/15], Loss: 0.4274\n",
            "Epoch [10/15], Loss: 0.4172\n",
            "Epoch [11/15], Loss: 0.3911\n",
            "Epoch [12/15], Loss: 0.3865\n",
            "Epoch [13/15], Loss: 0.3765\n",
            "Epoch [14/15], Loss: 0.3734\n",
            "Epoch [15/15], Loss: 0.3703\n",
            "Accuracy on the test set: 87.62%\n"
          ]
        }
      ]
    }
  ]
}